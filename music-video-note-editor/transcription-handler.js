// Transcription Handler - Transcri√ß√£o de √°udio para MIDI
// Integra√ß√£o com Spotify Basic Pitch / Magenta Onsets & Frames
// Para produ√ß√£o: use @spotify/basic-pitch ou Magenta.js

const TranscriptionHandler = {
    isProcessing: false,
    audioContext: null,
    analyser: null,

    // Inicializar Web Audio API
    initAudio() {
        if (!this.audioContext) {
            this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }
    },

    // Transcrever √°udio do v√≠deo atual
    async transcribeVideo() {
        if (this.isProcessing) {
            alert('J√° existe uma transcri√ß√£o em andamento...');
            return;
        }

        if (!appState.player) {
            alert('Carregue um v√≠deo primeiro!');
            return;
        }

        this.updateStatus('Preparando transcri√ß√£o...', 'info');
        this.isProcessing = true;

        try {
            // NOTA: Esta √© uma implementa√ß√£o simulada para demonstra√ß√£o
            // Para produ√ß√£o real, voc√™ precisaria:
            // 1. Extrair o √°udio do v√≠deo
            // 2. Processar com Basic Pitch ou Magenta Onsets & Frames
            // 3. Converter o resultado para notas

            this.updateStatus('‚ö†Ô∏è MODO DEMONSTRA√á√ÉO: Transcri√ß√£o simulada', 'warning');

            await this.simulateTranscription();

        } catch (error) {
            console.error('Erro na transcri√ß√£o:', error);
            this.updateStatus('Erro: ' + error.message, 'error');
        } finally {
            this.isProcessing = false;
        }
    },

    // Simula√ß√£o de transcri√ß√£o para demonstra√ß√£o
    async simulateTranscription() {
        this.updateStatus('Analisando √°udio... (0%)', 'info');

        // Simular progresso
        for (let i = 0; i <= 100; i += 10) {
            await this.sleep(200);
            this.updateStatus(`Analisando √°udio... (${i}%)`, 'info');
        }

        // Gerar algumas notas de exemplo baseadas na dura√ß√£o do v√≠deo
        const duration = appState.videoDuration || 60;
        const sampleNotes = this.generateSampleNotes(duration);

        this.updateStatus(`Transcri√ß√£o conclu√≠da! ${sampleNotes.length} notas detectadas.`, 'success');

        // Adicionar notas se op√ß√£o estiver marcada
        if (document.getElementById('autoAddTranscribedNotes').checked) {
            this.addTranscribedNotes(sampleNotes);
        }

        // Mostrar instru√ß√µes para integra√ß√£o real
        this.showRealIntegrationInfo();
    },

    // Gerar notas de exemplo (para demonstra√ß√£o)
    generateSampleNotes(duration) {
        const notes = [];
        const noteNames = ['C', 'D', 'E', 'F', 'G', 'A', 'B'];
        const octaves = [3, 4, 5];

        // Gerar notas a cada 2-4 segundos
        let currentTime = 0;
        while (currentTime < Math.min(duration, 30)) {
            const note = noteNames[Math.floor(Math.random() * noteNames.length)];
            const octave = octaves[Math.floor(Math.random() * octaves.length)];
            const noteDuration = 0.3 + Math.random() * 0.7; // 0.3-1.0s

            notes.push({
                note: note,
                octave: octave,
                startTime: currentTime,
                duration: noteDuration,
                confidence: 0.7 + Math.random() * 0.3 // 70-100%
            });

            currentTime += 2 + Math.random() * 2; // 2-4s
        }

        return notes;
    },

    // Adicionar notas transcritas ao projeto
    addTranscribedNotes(transcribedNotes) {
        const confidenceThreshold = document.getElementById('confidenceThreshold').value / 100;

        transcribedNotes.forEach(note => {
            if (note.confidence >= confidenceThreshold) {
                const newNote = {
                    id: Date.now() + Math.random(),
                    note: note.note,
                    octave: note.octave,
                    startTime: note.startTime,
                    duration: note.duration,
                    color: NOTE_COLORS[note.note],
                    source: 'transcription',
                    confidence: note.confidence
                };

                appState.notes.push(newNote);
            }
        });

        renderNotes();
        updateNotesList();

        const addedCount = transcribedNotes.filter(n => n.confidence >= confidenceThreshold).length;
        this.updateStatus(`${addedCount} notas adicionadas ao projeto!`, 'success');
    },

    // Mostrar informa√ß√µes sobre integra√ß√£o real
    showRealIntegrationInfo() {
        const info = `
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìò IMPLEMENTA√á√ÉO REAL - TRANSCRI√á√ÉO DE √ÅUDIO
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Esta √© uma DEMONSTRA√á√ÉO. Para implementa√ß√£o real, use:

üéµ OP√á√ÉO 1: Spotify Basic Pitch (Recomendado para MVP)
   - NPM: @spotify/basic-pitch
   - Leve, roda no browser com TensorFlow.js
   - GitHub: spotify/basic-pitch
   - Exemplo:
     import * as basicPitch from '@spotify/basic-pitch';
     const model = await basicPitch.loadModel();
     const frames = await basicPitch.detectNotes(audioData);

üéπ OP√á√ÉO 2: Magenta Onsets & Frames
   - Parte do projeto Magenta (Google)
   - √ìtimo para piano
   - Exemplo demo: Piano Scribe
   - CDN: https://cdn.jsdelivr.net/npm/@magenta/music

üîß OP√á√ÉO 3: Backend com ByteDance Piano Transcription
   - Melhor qualidade (deteta pedal tamb√©m!)
   - Requer Python + PyTorch + GPU
   - GitHub: bytedance/piano_transcription
   - Use FastAPI + Celery para processamento ass√≠ncrono

üì¶ INTEGRA√á√ÉO SUGERIDA:
   1. Frontend: Captura √°udio do v√≠deo (Web Audio API)
   2. Processa com Basic Pitch no browser OU
   3. Envia para backend (FastAPI) com modelo ByteDance
   4. Retorna MIDI/notas para visualiza√ß√£o

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        `.trim();

        console.log(info);
    },

    // Integra√ß√£o real com Basic Pitch (exemplo comentado)
    /*
    async transcribeWithBasicPitch(audioBuffer) {
        // Carregar modelo
        const model = await basicPitch.loadModel();

        // Processar √°udio
        const frames = await basicPitch.detectNotes(audioBuffer, {
            // Par√¢metros
            onsetThreshold: 0.5,
            frameThreshold: 0.3,
            minNoteLength: 0.1
        });

        // Converter para formato de notas
        const notes = frames.map(frame => ({
            note: this.midiToNoteName(frame.pitch),
            octave: Math.floor(frame.pitch / 12) - 1,
            startTime: frame.startTime,
            duration: frame.endTime - frame.startTime,
            confidence: frame.confidence
        }));

        return notes;
    },
    */

    // Converter n√∫mero MIDI para nome de nota
    midiToNoteName(midiNumber) {
        const noteNames = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
        return noteNames[midiNumber % 12];
    },

    // Atualizar status
    updateStatus(message, type = 'info') {
        const statusEl = document.getElementById('transcriptionStatus');
        if (statusEl) {
            statusEl.textContent = message;
            statusEl.className = 'status-message ' + type;
        }
    },

    // Utilit√°rio: sleep
    sleep(ms) {
        return new Promise(resolve => setTimeout(resolve, ms));
    }
};

// Event listener para o slider de confian√ßa
if (document.getElementById('confidenceThreshold')) {
    document.getElementById('confidenceThreshold').addEventListener('input', (e) => {
        document.getElementById('confidenceValue').textContent = e.target.value + '%';
    });
}
